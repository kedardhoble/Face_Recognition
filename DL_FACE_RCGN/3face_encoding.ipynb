{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jpg files into numpy arrays\n",
    "image = face_recognition.load_image_file(\"person.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the face encodings\n",
    "face_encodings = face_recognition.face_encodings(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20855848  0.01845226  0.05200075 -0.0191293  -0.02748848 -0.01855115\n",
      " -0.02725508 -0.01845027  0.1983559  -0.01124562  0.19645655  0.01600667\n",
      " -0.15621798 -0.08862405 -0.00915152  0.11604428 -0.12597212 -0.14229299\n",
      " -0.035728   -0.03505839  0.03726111  0.03980888 -0.07782649  0.07926036\n",
      " -0.14744234 -0.34706154 -0.1085614  -0.12216789  0.01723718 -0.11650671\n",
      "  0.06511284 -0.0390021  -0.18297054 -0.10930694  0.06847558  0.12637652\n",
      " -0.05037966 -0.09572254  0.13429841 -0.00703452 -0.16005874 -0.0557307\n",
      "  0.0843531   0.2744185   0.13435341  0.08523718  0.0049613  -0.11246417\n",
      "  0.1631324  -0.27373856  0.0840246   0.10128958  0.15344819  0.10832094\n",
      "  0.11609211 -0.09201843  0.07474767  0.25488392 -0.30816698  0.10207555\n",
      "  0.00198589 -0.01495526  0.03411688 -0.02620059  0.21705669  0.14441346\n",
      " -0.11093331 -0.12751684  0.17208107 -0.16183114 -0.04968157  0.12839445\n",
      " -0.03207505 -0.26411176 -0.31615111  0.07128872  0.36263987  0.1802815\n",
      " -0.13117111 -0.01013264 -0.05811099 -0.00737816  0.03560942  0.03457597\n",
      " -0.09948463 -0.06623527 -0.0577998  -0.01711864  0.24389172  0.12510215\n",
      "  0.00310599  0.16942377 -0.014172   -0.02782666  0.00143103  0.06574458\n",
      " -0.10071295  0.0066465  -0.07640252 -0.06614342  0.03114725  0.03002066\n",
      "  0.07674069  0.13323899 -0.21063028  0.15302029 -0.0154897  -0.04833609\n",
      "  0.00523032 -0.02149023 -0.06463667  0.01915047  0.14195825 -0.29341784\n",
      "  0.22209312  0.12297863  0.04837452  0.15621081  0.0021563   0.00968097\n",
      " -0.03717988 -0.11729008 -0.17494749 -0.01424959  0.05999133 -0.07590416\n",
      "  0.07595529 -0.00694479]\n"
     ]
    }
   ],
   "source": [
    "if len(face_encodings) == 0:\n",
    "    # No faces found in the image.\n",
    "    print(\"No faces were found.\")\n",
    "\n",
    "else:\n",
    "    # Grab the first face encoding\n",
    "    first_face_encoding = face_encodings[0]\n",
    "\n",
    "    # Print the results\n",
    "    print(first_face_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
